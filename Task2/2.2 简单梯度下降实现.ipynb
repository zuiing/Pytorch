{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 简单梯度下降实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 对 y=x^2+2*x+1进行梯度下降 \n",
    "#### 1.用Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9637202944000001\n"
     ]
    }
   ],
   "source": [
    "x =5 # x初始值  \n",
    "learning_rate =0.2 #学习率\n",
    "epoches =10\n",
    "y =lambda x:x**2 +2*x+1 #简单曲线\n",
    "for epoch in range(epoches):\n",
    "    dx =2*x+2\n",
    "    x = x-learning_rate*dx;\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad: None  data tensor([[0.0982]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x=torch.randn(1,1,requires_grad=True) # x取随机值\n",
    "print('grad:',x.grad,\" data\",x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "设置学习率及学习周期"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate =0.1\n",
    "epoches =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad tensor([[2.1964]])\n",
      "grad tensor([[1.7571]])\n",
      "grad tensor([[1.4057]])\n",
      "grad tensor([[1.1246]])\n",
      "grad tensor([[0.8996]])\n",
      "grad tensor([[0.7197]])\n",
      "grad tensor([[0.5758]])\n",
      "grad tensor([[0.4606]])\n",
      "grad tensor([[0.3685]])\n",
      "grad tensor([[0.2948]])\n",
      "tensor([[-0.8821]])\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epoches):\n",
    "     y = x**2+2*x+1\n",
    "     y.backward()\n",
    "     print(\"grad\",x.grad.data) #x的梯度值\n",
    "     x.data = x.data - learning_rate*x.grad.data #更新x\n",
    "     x.grad.data.zero_()\n",
    "print(x.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.  Python+Numpy拟合简单曲线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9999999999965319\n",
      "[84.0, 0.3733333333333322, 0.0016592592592593162, 7.374485596702598e-06, 3.27754915409057e-08, 1.4566885129490257e-10, 6.474171173496756e-13, 2.877409334547812e-15, 1.2788488946338218e-17, 5.683796199670706e-20]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_data = np.array([1.,2.,3])\n",
    "y_data = np.array([2,4,6])\n",
    "\n",
    "epoches = 10\n",
    "\n",
    "lr =0.1\n",
    "w = 0 \n",
    "cost = []\n",
    "\n",
    "for epoch in range(epoches):\n",
    "    y_pred = x_data*w\n",
    "    loss = (y_pred - y_data)**2/2*len(x_data)\n",
    "    cost.append(sum(loss))\n",
    "    #print(cost)\n",
    "    dw = -2 *(y_data-y_pred)@x_data.T/x_data.shape[0]\n",
    "    w = w - lr*dw\n",
    "    \n",
    "print(w)\n",
    "print(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Pytorch拟合简单曲线 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x_data = torch.Tensor([[1.0],[2.0],[3.0]])\n",
    "y_data = torch.Tensor([[2.0],[4.0],[6.0]])\n",
    "epoches = 10\n",
    "\n",
    "lr =0.1\n",
    "w =torch.zeros(1,1,requires_grad =True)\n",
    "#print(w.data)\n",
    "cost = []\n",
    "for epoch in range(epoches):\n",
    "    y_pred = x_data*w\n",
    "   # print(y_pred)\n",
    "    #Loss\n",
    "    loss = torch.mean((y_pred-y_data)**2)\n",
    "    #print(loss.data)\n",
    "   # print(loss.data.numpy())\n",
    "    cost.append(loss.data.item())\n",
    "    #print(cost)\n",
    "    #print(cost)\n",
    "    loss.backward()\n",
    "    #print(w.grad.data)\n",
    "    #参数更新\n",
    "    w.data = w.data - lr*w.grad.data\n",
    "    w.grad.data.zero_()\n",
    "\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  numpy和pytorch实现线性回归"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Numpy实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 2.565443781623136e-08\n",
      "w1: 1.9999674457769208 w2 -3.999977280651687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "from matplotlib import style\n",
    "\n",
    "#创建数据\n",
    "N = 100\n",
    "x1 = np.linspace(-10, 10, N)\n",
    "x2 = np.linspace(-15, 5, N)\n",
    "\n",
    "x = np.concatenate(([x1], [x2]), axis=0).T\n",
    "w = np.array([2, -4])\n",
    "y = np.dot(x, w)\n",
    "fig = plt.figure()\n",
    "ax1 = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "ax1.plot_wireframe(np.array([x1]),np.array([x2]),np.array([y]), rstride=5, cstride=5)\n",
    "ax1.set_xlabel(\"x1\")\n",
    "ax1.set_ylabel(\"x2\")\n",
    "ax1.set_zlabel(\"y\")\n",
    "\n",
    "#梯度下降\n",
    "EPOCHS = 50 #迭代总次数\n",
    "LOSS_MIN = 0.0001 #loss的目标最小值，当loss小于此值时停止迭代\n",
    "lr = 0.01\n",
    "# w_GD = np.random.rand(2) #梯度下降(GD)过程中存储w的值\n",
    "w_GD = np.zeros(2)\n",
    "\n",
    "cost = [] #梯度下降(GD)过程中存储loss的值\n",
    "w_all = []\n",
    "for i in range(EPOCHS):\n",
    "    w_all.append(w_GD.copy())\n",
    "    y_predict = np.dot(x, w_GD) #使用当前w_GD的y预测值\n",
    "    loss = np.mean((y_predict-y)**2) #计算loss\n",
    "    cost.append(loss)\n",
    "    dw = np.mean(2*(y_predict-y) * x.T, axis=1) #计算梯度\n",
    "    w_GD -= lr*dw #梯度下降\n",
    "    \n",
    "print(\"loss:\",loss)\n",
    "print(\"w1:\",w_GD[0],\"w2\",w_GD[1])\n",
    "\n",
    "#画出梯度下降曲线\n",
    "w_all = np.array(w_all)\n",
    "fig = plt.figure()\n",
    "ax2 = fig.add_subplot(111, projection='3d')\n",
    "ax2.plot_wireframe(np.array([w_all[:,0]]),np.array([w_all[:,1]]),np.array([cost]))\n",
    "ax2.set_xlabel(\"w1\")\n",
    "ax2.set_ylabel(\"w2\")\n",
    "ax2.set_zlabel(\"loss\")\n",
    "fig = plt.figure()\n",
    "\n",
    "#画出loss-iteration曲线\n",
    "plt.plot(range(len(cost)),cost)\n",
    "plt.title('loss')\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Pytorch实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(9.4182e-11, grad_fn=<MeanBackward0>)\n",
      "w_GD: tensor([ 2.0000, -4.0000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "N = 100\n",
    "x = Variable(torch.randn(N,2))\n",
    "w = Variable(torch.FloatTensor([2, -4]))\n",
    "y = x*w\n",
    "\n",
    "EPOCHS = 5000\n",
    "\n",
    "lr = 0.01\n",
    "w_GD = Variable(torch.FloatTensor([0, 0]), requires_grad=True)\n",
    "cost = []\n",
    "w_all = []\n",
    "for i in range(EPOCHS):\n",
    "    w_all.append(w_GD.data)\n",
    "    y_predict = x*w_GD\n",
    "    loss = torch.mean((y_predict-y)**2)\n",
    "\n",
    "    cost.append(loss.data.numpy())\n",
    "    loss.backward()\n",
    "     #参数更新\n",
    "    w_GD.data -= lr*w_GD.grad.data\n",
    "    w_GD.grad.data.zero_()    \n",
    "print(\"loss:\",loss)\n",
    "print(\"w_GD:\",w_GD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
